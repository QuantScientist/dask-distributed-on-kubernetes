{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tim/venvs/py3/lib/python3.4/site-packages/matplotlib/__init__.py:872: UserWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "# mhcflurry_cloud example\n",
    "# Runs cross validation over a few models.\n",
    "#\n",
    "import mhcflurry_cloud\n",
    "import mhcflurry\n",
    "import fancyimpute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset(n=137654, alleles=['ELA-A1', 'Gogo-B0101', 'H-2-DB', 'H-2-DD', 'H-2-KB', 'H-2-KD', 'H-2-KK', 'H-2-LD', 'HLA-A0101', 'HLA-A0201', 'HLA-A0202', 'HLA-A0203', 'HLA-A0205', 'HLA-A0206', 'HLA-A0207', 'HLA-A0210', 'HLA-A0211', 'HLA-A0212', 'HLA-A0216', 'HLA-A0219', 'HLA-A0250', 'HLA-A0301', 'HLA-A0302', 'HLA-A11', 'HLA-A1101', 'HLA-A2', 'HLA-A2301', 'HLA-A2402', 'HLA-A2403', 'HLA-A2501', 'HLA-A26', 'HLA-A2601', 'HLA-A2602', 'HLA-A2603', 'HLA-A2902', 'HLA-A3001', 'HLA-A3002', 'HLA-A3101', 'HLA-A3201', 'HLA-A3301', 'HLA-A6601', 'HLA-A6801', 'HLA-A6802', 'HLA-A6901', 'HLA-A8001', 'HLA-B0702', 'HLA-B0801', 'HLA-B0802', 'HLA-B0803', 'HLA-B1402', 'HLA-B1501', 'HLA-B1502', 'HLA-B1503', 'HLA-B1509', 'HLA-B1517', 'HLA-B1801', 'HLA-B2701', 'HLA-B2702', 'HLA-B2703', 'HLA-B2705', 'HLA-B3501', 'HLA-B3503', 'HLA-B3508', 'HLA-B3801', 'HLA-B3901', 'HLA-B4001', 'HLA-B4002', 'HLA-B4201', 'HLA-B44', 'HLA-B4402', 'HLA-B4403', 'HLA-B4501', 'HLA-B4601', 'HLA-B4801', 'HLA-B5101', 'HLA-B5301', 'HLA-B5401', 'HLA-B5701', 'HLA-B5801', 'HLA-B5802', 'HLA-B7', 'HLA-B7301', 'HLA-E0101', 'Mamu-A01', 'Mamu-A02', 'Mamu-A07', 'Mamu-A11', 'Mamu-A2201', 'Mamu-A2601', 'Mamu-B01', 'Mamu-B03', 'Mamu-B04', 'Mamu-B08', 'Mamu-B17', 'Mamu-B52', 'Patr-A0101', 'Patr-A0301', 'Patr-A0401', 'Patr-A0602', 'Patr-A0701', 'Patr-A0901', 'Patr-B0101', 'Patr-B0901', 'Patr-B1301', 'Patr-B1701', 'Patr-B2401'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load some data.\n",
    "train_data = mhcflurry.dataset.Dataset.from_csv(\"../test/data/bdata.2009.mhci.public.1.txt\")\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:   27.9s remaining:   27.9s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:   38.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[AlleleSpecificTrainTestFold(allele='HLA-A0201', train=Dataset(n=6376, alleles=['HLA-A0201']), imputed_train=Dataset(n=19167, alleles=['HLA-A0201']), test=Dataset(n=1486, alleles=['HLA-A0201'])),\n",
       " AlleleSpecificTrainTestFold(allele='HLA-A0201', train=Dataset(n=6377, alleles=['HLA-A0201']), imputed_train=Dataset(n=19153, alleles=['HLA-A0201']), test=Dataset(n=1526, alleles=['HLA-A0201'])),\n",
       " AlleleSpecificTrainTestFold(allele='HLA-A0201', train=Dataset(n=6377, alleles=['HLA-A0201']), imputed_train=Dataset(n=19138, alleles=['HLA-A0201']), test=Dataset(n=1477, alleles=['HLA-A0201'])),\n",
       " AlleleSpecificTrainTestFold(allele='HLA-A0202', train=Dataset(n=2612, alleles=['HLA-A0202']), imputed_train=Dataset(n=19304, alleles=['HLA-A0202']), test=Dataset(n=716, alleles=['HLA-A0202'])),\n",
       " AlleleSpecificTrainTestFold(allele='HLA-A0202', train=Dataset(n=2613, alleles=['HLA-A0202']), imputed_train=Dataset(n=19304, alleles=['HLA-A0202']), test=Dataset(n=709, alleles=['HLA-A0202'])),\n",
       " AlleleSpecificTrainTestFold(allele='HLA-A0202', train=Dataset(n=2613, alleles=['HLA-A0202']), imputed_train=Dataset(n=19304, alleles=['HLA-A0202']), test=Dataset(n=717, alleles=['HLA-A0202']))]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate cross validation folds, with imputation.\n",
    "imputer = fancyimpute.MICE(n_imputations=2, n_burn_in=1, n_nearest_columns=25)\n",
    "\n",
    "folds = mhcflurry_cloud.cross_validation_folds(\n",
    "    train_data,\n",
    "    n_folds=3,\n",
    "    imputer=imputer,\n",
    "    drop_similar_peptides=True,\n",
    "    alleles=[\"HLA-A0201\", \"HLA-A0202\"],\n",
    "    n_jobs=-1,\n",
    "    verbose=5,\n",
    ")\n",
    "folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'activation': 'tanh',\n",
       "  'batch_size': 128,\n",
       "  'dropout_probability': 0.5,\n",
       "  'embedding_output_dim': 8,\n",
       "  'fraction_negative': 0.2,\n",
       "  'impute': False,\n",
       "  'layer_sizes': [4],\n",
       "  'max_ic50': 50000,\n",
       "  'n_training_epochs': 3,\n",
       "  'pretrain_decay': '1 / (1+epoch)**2'},\n",
       " {'activation': 'relu',\n",
       "  'batch_size': 128,\n",
       "  'dropout_probability': 0.5,\n",
       "  'embedding_output_dim': 8,\n",
       "  'fraction_negative': 0.2,\n",
       "  'impute': False,\n",
       "  'layer_sizes': [4],\n",
       "  'max_ic50': 50000,\n",
       "  'n_training_epochs': 3,\n",
       "  'pretrain_decay': '1 / (1+epoch)**2'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make some models.\n",
    "models = mhcflurry_cloud.models_grid(\n",
    "    activation=[\"tanh\", \"relu\"],\n",
    "    layer_sizes=[[4]],\n",
    "    embedding_output_dim=[8],\n",
    "    n_training_epochs=[3])\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tim/venvs/py3/lib/python3.4/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>allele</th>\n",
       "      <th>fold_num</th>\n",
       "      <th>model_num</th>\n",
       "      <th>train_size</th>\n",
       "      <th>test_size</th>\n",
       "      <th>imputed_train_size</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>train_tau</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_auc</th>\n",
       "      <th>...</th>\n",
       "      <th>model_fraction_negative</th>\n",
       "      <th>model_embedding_output_dim</th>\n",
       "      <th>model_activation</th>\n",
       "      <th>model_batch_size</th>\n",
       "      <th>model_max_ic50</th>\n",
       "      <th>model_dropout_probability</th>\n",
       "      <th>model_layer_sizes</th>\n",
       "      <th>model_n_training_epochs</th>\n",
       "      <th>model_impute</th>\n",
       "      <th>model_pretrain_decay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HLA-A0201</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6376</td>\n",
       "      <td>1486</td>\n",
       "      <td>19167</td>\n",
       "      <td>0.860319</td>\n",
       "      <td>0.466539</td>\n",
       "      <td>0.458217</td>\n",
       "      <td>0.877381</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>8</td>\n",
       "      <td>tanh</td>\n",
       "      <td>128</td>\n",
       "      <td>50000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>[4]</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>1 / (1+epoch)**2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HLA-A0201</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6376</td>\n",
       "      <td>1486</td>\n",
       "      <td>19167</td>\n",
       "      <td>0.764980</td>\n",
       "      <td>0.331552</td>\n",
       "      <td>0.061980</td>\n",
       "      <td>0.754046</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>8</td>\n",
       "      <td>relu</td>\n",
       "      <td>128</td>\n",
       "      <td>50000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>[4]</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>1 / (1+epoch)**2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HLA-A0201</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6377</td>\n",
       "      <td>1526</td>\n",
       "      <td>19153</td>\n",
       "      <td>0.858363</td>\n",
       "      <td>0.452435</td>\n",
       "      <td>0.473381</td>\n",
       "      <td>0.869996</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>8</td>\n",
       "      <td>tanh</td>\n",
       "      <td>128</td>\n",
       "      <td>50000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>[4]</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>1 / (1+epoch)**2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HLA-A0201</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6377</td>\n",
       "      <td>1526</td>\n",
       "      <td>19153</td>\n",
       "      <td>0.861165</td>\n",
       "      <td>0.464758</td>\n",
       "      <td>0.410350</td>\n",
       "      <td>0.858737</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>8</td>\n",
       "      <td>relu</td>\n",
       "      <td>128</td>\n",
       "      <td>50000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>[4]</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>1 / (1+epoch)**2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HLA-A0201</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6377</td>\n",
       "      <td>1477</td>\n",
       "      <td>19138</td>\n",
       "      <td>0.895173</td>\n",
       "      <td>0.509815</td>\n",
       "      <td>0.499332</td>\n",
       "      <td>0.878287</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>8</td>\n",
       "      <td>tanh</td>\n",
       "      <td>128</td>\n",
       "      <td>50000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>[4]</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>1 / (1+epoch)**2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HLA-A0201</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6377</td>\n",
       "      <td>1477</td>\n",
       "      <td>19138</td>\n",
       "      <td>0.801731</td>\n",
       "      <td>0.381375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.796867</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>8</td>\n",
       "      <td>relu</td>\n",
       "      <td>128</td>\n",
       "      <td>50000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>[4]</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>1 / (1+epoch)**2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HLA-A0202</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2612</td>\n",
       "      <td>716</td>\n",
       "      <td>19304</td>\n",
       "      <td>0.700828</td>\n",
       "      <td>0.266966</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.651194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>8</td>\n",
       "      <td>tanh</td>\n",
       "      <td>128</td>\n",
       "      <td>50000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>[4]</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>1 / (1+epoch)**2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HLA-A0202</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2612</td>\n",
       "      <td>716</td>\n",
       "      <td>19304</td>\n",
       "      <td>0.693713</td>\n",
       "      <td>0.236269</td>\n",
       "      <td>0.320106</td>\n",
       "      <td>0.658918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>8</td>\n",
       "      <td>relu</td>\n",
       "      <td>128</td>\n",
       "      <td>50000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>[4]</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>1 / (1+epoch)**2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HLA-A0202</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2613</td>\n",
       "      <td>709</td>\n",
       "      <td>19304</td>\n",
       "      <td>0.790069</td>\n",
       "      <td>0.383208</td>\n",
       "      <td>0.690281</td>\n",
       "      <td>0.829016</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>8</td>\n",
       "      <td>tanh</td>\n",
       "      <td>128</td>\n",
       "      <td>50000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>[4]</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>1 / (1+epoch)**2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HLA-A0202</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2613</td>\n",
       "      <td>709</td>\n",
       "      <td>19304</td>\n",
       "      <td>0.657681</td>\n",
       "      <td>0.228233</td>\n",
       "      <td>0.621395</td>\n",
       "      <td>0.681189</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>8</td>\n",
       "      <td>relu</td>\n",
       "      <td>128</td>\n",
       "      <td>50000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>[4]</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>1 / (1+epoch)**2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HLA-A0202</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2613</td>\n",
       "      <td>717</td>\n",
       "      <td>19304</td>\n",
       "      <td>0.769510</td>\n",
       "      <td>0.357526</td>\n",
       "      <td>0.637655</td>\n",
       "      <td>0.745321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>8</td>\n",
       "      <td>tanh</td>\n",
       "      <td>128</td>\n",
       "      <td>50000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>[4]</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>1 / (1+epoch)**2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>HLA-A0202</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2613</td>\n",
       "      <td>717</td>\n",
       "      <td>19304</td>\n",
       "      <td>0.724291</td>\n",
       "      <td>0.305307</td>\n",
       "      <td>0.449242</td>\n",
       "      <td>0.715569</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>8</td>\n",
       "      <td>relu</td>\n",
       "      <td>128</td>\n",
       "      <td>50000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>[4]</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>1 / (1+epoch)**2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       allele  fold_num  model_num  train_size  test_size  imputed_train_size  \\\n",
       "0   HLA-A0201         0          0        6376       1486               19167   \n",
       "1   HLA-A0201         0          1        6376       1486               19167   \n",
       "2   HLA-A0201         1          0        6377       1526               19153   \n",
       "3   HLA-A0201         1          1        6377       1526               19153   \n",
       "4   HLA-A0201         2          0        6377       1477               19138   \n",
       "5   HLA-A0201         2          1        6377       1477               19138   \n",
       "6   HLA-A0202         3          0        2612        716               19304   \n",
       "7   HLA-A0202         3          1        2612        716               19304   \n",
       "8   HLA-A0202         4          0        2613        709               19304   \n",
       "9   HLA-A0202         4          1        2613        709               19304   \n",
       "10  HLA-A0202         5          0        2613        717               19304   \n",
       "11  HLA-A0202         5          1        2613        717               19304   \n",
       "\n",
       "    train_auc  train_tau  train_f1  test_auc         ...           \\\n",
       "0    0.860319   0.466539  0.458217  0.877381         ...            \n",
       "1    0.764980   0.331552  0.061980  0.754046         ...            \n",
       "2    0.858363   0.452435  0.473381  0.869996         ...            \n",
       "3    0.861165   0.464758  0.410350  0.858737         ...            \n",
       "4    0.895173   0.509815  0.499332  0.878287         ...            \n",
       "5    0.801731   0.381375  0.000000  0.796867         ...            \n",
       "6    0.700828   0.266966  0.571429  0.651194         ...            \n",
       "7    0.693713   0.236269  0.320106  0.658918         ...            \n",
       "8    0.790069   0.383208  0.690281  0.829016         ...            \n",
       "9    0.657681   0.228233  0.621395  0.681189         ...            \n",
       "10   0.769510   0.357526  0.637655  0.745321         ...            \n",
       "11   0.724291   0.305307  0.449242  0.715569         ...            \n",
       "\n",
       "    model_fraction_negative  model_embedding_output_dim  model_activation  \\\n",
       "0                       0.2                           8              tanh   \n",
       "1                       0.2                           8              relu   \n",
       "2                       0.2                           8              tanh   \n",
       "3                       0.2                           8              relu   \n",
       "4                       0.2                           8              tanh   \n",
       "5                       0.2                           8              relu   \n",
       "6                       0.2                           8              tanh   \n",
       "7                       0.2                           8              relu   \n",
       "8                       0.2                           8              tanh   \n",
       "9                       0.2                           8              relu   \n",
       "10                      0.2                           8              tanh   \n",
       "11                      0.2                           8              relu   \n",
       "\n",
       "    model_batch_size  model_max_ic50 model_dropout_probability  \\\n",
       "0                128           50000                       0.5   \n",
       "1                128           50000                       0.5   \n",
       "2                128           50000                       0.5   \n",
       "3                128           50000                       0.5   \n",
       "4                128           50000                       0.5   \n",
       "5                128           50000                       0.5   \n",
       "6                128           50000                       0.5   \n",
       "7                128           50000                       0.5   \n",
       "8                128           50000                       0.5   \n",
       "9                128           50000                       0.5   \n",
       "10               128           50000                       0.5   \n",
       "11               128           50000                       0.5   \n",
       "\n",
       "    model_layer_sizes  model_n_training_epochs  model_impute  \\\n",
       "0                 [4]                        3         False   \n",
       "1                 [4]                        3         False   \n",
       "2                 [4]                        3         False   \n",
       "3                 [4]                        3         False   \n",
       "4                 [4]                        3         False   \n",
       "5                 [4]                        3         False   \n",
       "6                 [4]                        3         False   \n",
       "7                 [4]                        3         False   \n",
       "8                 [4]                        3         False   \n",
       "9                 [4]                        3         False   \n",
       "10                [4]                        3         False   \n",
       "11                [4]                        3         False   \n",
       "\n",
       "   model_pretrain_decay  \n",
       "0      1 / (1+epoch)**2  \n",
       "1      1 / (1+epoch)**2  \n",
       "2      1 / (1+epoch)**2  \n",
       "3      1 / (1+epoch)**2  \n",
       "4      1 / (1+epoch)**2  \n",
       "5      1 / (1+epoch)**2  \n",
       "6      1 / (1+epoch)**2  \n",
       "7      1 / (1+epoch)**2  \n",
       "8      1 / (1+epoch)**2  \n",
       "9      1 / (1+epoch)**2  \n",
       "10     1 / (1+epoch)**2  \n",
       "11     1 / (1+epoch)**2  \n",
       "\n",
       "[12 rows x 23 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and test models on the folds.\n",
    "df = mhcflurry_cloud.train_across_models_and_folds(folds, models)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [py3k]",
   "language": "python",
   "name": "Python [py3k]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
