{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "import distributed, sys, joblib\n",
    "import mhcflurry, mhcflurry_cloud\n",
    "import joblib.parallel\n",
    "from joblib import Parallel\n",
    "from joblib.parallel import register_parallel_backend, parallel_backend\n",
    "from distributed.joblib import DistributedBackend\n",
    "register_parallel_backend('distributed', DistributedBackend)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#executor = distributed.Executor('127.0.0.1:8786')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "root - INFO - Allele: HLA-A0201\n",
      "root - INFO - After dropping similar peptides, test size 3189->1525\n",
      "root - INFO - After dropping similar peptides, test size 3188->1539\n",
      "root - INFO - After dropping similar peptides, test size 3188->1423\n",
      "root - INFO - Allele: HLA-A0301\n",
      "root - INFO - After dropping similar peptides, test size 2047->1134\n",
      "root - INFO - After dropping similar peptides, test size 2047->1073\n",
      "root - INFO - After dropping similar peptides, test size 2047->1084\n",
      "root - INFO - Allele: HLA-A1101\n",
      "root - INFO - After dropping similar peptides, test size 1800->1019\n",
      "root - INFO - After dropping similar peptides, test size 1800->998\n",
      "root - INFO - After dropping similar peptides, test size 1799->982\n",
      "root - INFO - Allele: HLA-A0203\n",
      "root - INFO - After dropping similar peptides, test size 1848->980\n",
      "root - INFO - After dropping similar peptides, test size 1847->955\n",
      "root - INFO - After dropping similar peptides, test size 1847->984\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[AlleleSpecificTrainTestFold(allele='HLA-A0201', train=Dataset(n=6376, alleles=['HLA-A0201']), imputed_train=None, test=Dataset(n=1525, alleles=['HLA-A0201'])),\n",
       " AlleleSpecificTrainTestFold(allele='HLA-A0201', train=Dataset(n=6377, alleles=['HLA-A0201']), imputed_train=None, test=Dataset(n=1539, alleles=['HLA-A0201'])),\n",
       " AlleleSpecificTrainTestFold(allele='HLA-A0201', train=Dataset(n=6377, alleles=['HLA-A0201']), imputed_train=None, test=Dataset(n=1423, alleles=['HLA-A0201'])),\n",
       " AlleleSpecificTrainTestFold(allele='HLA-A0301', train=Dataset(n=4094, alleles=['HLA-A0301']), imputed_train=None, test=Dataset(n=1134, alleles=['HLA-A0301'])),\n",
       " AlleleSpecificTrainTestFold(allele='HLA-A0301', train=Dataset(n=4094, alleles=['HLA-A0301']), imputed_train=None, test=Dataset(n=1073, alleles=['HLA-A0301'])),\n",
       " AlleleSpecificTrainTestFold(allele='HLA-A0301', train=Dataset(n=4094, alleles=['HLA-A0301']), imputed_train=None, test=Dataset(n=1084, alleles=['HLA-A0301'])),\n",
       " AlleleSpecificTrainTestFold(allele='HLA-A1101', train=Dataset(n=3599, alleles=['HLA-A1101']), imputed_train=None, test=Dataset(n=1019, alleles=['HLA-A1101'])),\n",
       " AlleleSpecificTrainTestFold(allele='HLA-A1101', train=Dataset(n=3599, alleles=['HLA-A1101']), imputed_train=None, test=Dataset(n=998, alleles=['HLA-A1101'])),\n",
       " AlleleSpecificTrainTestFold(allele='HLA-A1101', train=Dataset(n=3600, alleles=['HLA-A1101']), imputed_train=None, test=Dataset(n=982, alleles=['HLA-A1101'])),\n",
       " AlleleSpecificTrainTestFold(allele='HLA-A0203', train=Dataset(n=3694, alleles=['HLA-A0203']), imputed_train=None, test=Dataset(n=980, alleles=['HLA-A0203'])),\n",
       " AlleleSpecificTrainTestFold(allele='HLA-A0203', train=Dataset(n=3695, alleles=['HLA-A0203']), imputed_train=None, test=Dataset(n=955, alleles=['HLA-A0203'])),\n",
       " AlleleSpecificTrainTestFold(allele='HLA-A0203', train=Dataset(n=3695, alleles=['HLA-A0203']), imputed_train=None, test=Dataset(n=984, alleles=['HLA-A0203']))]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load some data.\n",
    "full_train_data = mhcflurry.dataset.Dataset.from_csv(\"../test/data/bdata.2009.mhci.public.1.txt\")\n",
    "train_data = full_train_data.filter_alleles_by_count(5000)\n",
    "\n",
    "# Generate cross validation folds, with imputation.\n",
    "#imputer = fancyimpute.MICE(n_imputations=2, n_burn_in=1, n_nearest_columns=25)\n",
    "\n",
    "\n",
    "folds = mhcflurry_cloud.cross_validation_folds(\n",
    "    train_data,\n",
    "    n_folds=3,\n",
    "    imputer=None,\n",
    "    drop_similar_peptides=True,\n",
    "    #alleles=[\"HLA-A0201\", \"HLA-A0202\"],\n",
    "    n_jobs=-1,\n",
    "    verbose=5,\n",
    ")\n",
    "folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'activation': 'tanh',\n",
       "  'batch_size': 128,\n",
       "  'dropout_probability': 0.5,\n",
       "  'embedding_output_dim': 8,\n",
       "  'fraction_negative': 0.2,\n",
       "  'impute': False,\n",
       "  'layer_sizes': [4],\n",
       "  'max_ic50': 50000,\n",
       "  'n_training_epochs': 3,\n",
       "  'pretrain_decay': '1 / (1+epoch)**2'},\n",
       " {'activation': 'relu',\n",
       "  'batch_size': 128,\n",
       "  'dropout_probability': 0.5,\n",
       "  'embedding_output_dim': 8,\n",
       "  'fraction_negative': 0.2,\n",
       "  'impute': False,\n",
       "  'layer_sizes': [4],\n",
       "  'max_ic50': 50000,\n",
       "  'n_training_epochs': 3,\n",
       "  'pretrain_decay': '1 / (1+epoch)**2'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make some models.\n",
    "models = mhcflurry_cloud.models_grid(\n",
    "    activation=[\"tanh\", \"relu\"],\n",
    "    layer_sizes=[[4]],\n",
    "    embedding_output_dim=[8],\n",
    "    n_training_epochs=[3])\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "root - INFO - Training 2 architectures on 12 folds = 24 predictors.\n",
      "root - INFO - Done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>allele</th>\n",
       "      <th>fold_num</th>\n",
       "      <th>model_num</th>\n",
       "      <th>train_size</th>\n",
       "      <th>test_size</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_tau</th>\n",
       "      <th>test_auc</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>...</th>\n",
       "      <th>model_impute</th>\n",
       "      <th>model_activation</th>\n",
       "      <th>model_layer_sizes</th>\n",
       "      <th>model_batch_size</th>\n",
       "      <th>model_fraction_negative</th>\n",
       "      <th>model_n_training_epochs</th>\n",
       "      <th>model_embedding_output_dim</th>\n",
       "      <th>model_pretrain_decay</th>\n",
       "      <th>model_dropout_probability</th>\n",
       "      <th>model_max_ic50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HLA-A0201</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6376</td>\n",
       "      <td>1525</td>\n",
       "      <td>0.895284</td>\n",
       "      <td>0.587408</td>\n",
       "      <td>0.517057</td>\n",
       "      <td>0.892627</td>\n",
       "      <td>0.540448</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>tanh</td>\n",
       "      <td>[4]</td>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1 / (1+epoch)**2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HLA-A0201</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6376</td>\n",
       "      <td>1525</td>\n",
       "      <td>0.826558</td>\n",
       "      <td>0.099691</td>\n",
       "      <td>0.413170</td>\n",
       "      <td>0.819003</td>\n",
       "      <td>0.043796</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>relu</td>\n",
       "      <td>[4]</td>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1 / (1+epoch)**2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HLA-A0201</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6377</td>\n",
       "      <td>1539</td>\n",
       "      <td>0.885063</td>\n",
       "      <td>0.492090</td>\n",
       "      <td>0.496178</td>\n",
       "      <td>0.894675</td>\n",
       "      <td>0.408759</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>tanh</td>\n",
       "      <td>[4]</td>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1 / (1+epoch)**2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HLA-A0201</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6377</td>\n",
       "      <td>1539</td>\n",
       "      <td>0.849540</td>\n",
       "      <td>0.398695</td>\n",
       "      <td>0.445013</td>\n",
       "      <td>0.850579</td>\n",
       "      <td>0.366300</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>relu</td>\n",
       "      <td>[4]</td>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1 / (1+epoch)**2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HLA-A0201</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6377</td>\n",
       "      <td>1423</td>\n",
       "      <td>0.871091</td>\n",
       "      <td>0.513023</td>\n",
       "      <td>0.467363</td>\n",
       "      <td>0.874031</td>\n",
       "      <td>0.472998</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>tanh</td>\n",
       "      <td>[4]</td>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1 / (1+epoch)**2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HLA-A0201</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6377</td>\n",
       "      <td>1423</td>\n",
       "      <td>0.855029</td>\n",
       "      <td>0.250103</td>\n",
       "      <td>0.440961</td>\n",
       "      <td>0.863000</td>\n",
       "      <td>0.226328</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>relu</td>\n",
       "      <td>[4]</td>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1 / (1+epoch)**2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HLA-A0301</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4094</td>\n",
       "      <td>1134</td>\n",
       "      <td>0.800724</td>\n",
       "      <td>0.460327</td>\n",
       "      <td>0.352416</td>\n",
       "      <td>0.789823</td>\n",
       "      <td>0.474725</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>tanh</td>\n",
       "      <td>[4]</td>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1 / (1+epoch)**2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HLA-A0301</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4094</td>\n",
       "      <td>1134</td>\n",
       "      <td>0.705915</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.249910</td>\n",
       "      <td>0.698282</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>relu</td>\n",
       "      <td>[4]</td>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1 / (1+epoch)**2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HLA-A0301</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4094</td>\n",
       "      <td>1073</td>\n",
       "      <td>0.814982</td>\n",
       "      <td>0.495316</td>\n",
       "      <td>0.390080</td>\n",
       "      <td>0.844880</td>\n",
       "      <td>0.430380</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>tanh</td>\n",
       "      <td>[4]</td>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1 / (1+epoch)**2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HLA-A0301</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4094</td>\n",
       "      <td>1073</td>\n",
       "      <td>0.763060</td>\n",
       "      <td>0.192000</td>\n",
       "      <td>0.320746</td>\n",
       "      <td>0.755124</td>\n",
       "      <td>0.210863</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>relu</td>\n",
       "      <td>[4]</td>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1 / (1+epoch)**2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HLA-A0301</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4094</td>\n",
       "      <td>1084</td>\n",
       "      <td>0.820866</td>\n",
       "      <td>0.509576</td>\n",
       "      <td>0.396576</td>\n",
       "      <td>0.801169</td>\n",
       "      <td>0.461176</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>tanh</td>\n",
       "      <td>[4]</td>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1 / (1+epoch)**2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>HLA-A0301</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4094</td>\n",
       "      <td>1084</td>\n",
       "      <td>0.729144</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.292090</td>\n",
       "      <td>0.677374</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>relu</td>\n",
       "      <td>[4]</td>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1 / (1+epoch)**2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>HLA-A1101</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3599</td>\n",
       "      <td>1019</td>\n",
       "      <td>0.850511</td>\n",
       "      <td>0.656062</td>\n",
       "      <td>0.464920</td>\n",
       "      <td>0.859400</td>\n",
       "      <td>0.678843</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>tanh</td>\n",
       "      <td>[4]</td>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1 / (1+epoch)**2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>HLA-A1101</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3599</td>\n",
       "      <td>1019</td>\n",
       "      <td>0.715559</td>\n",
       "      <td>0.120120</td>\n",
       "      <td>0.285154</td>\n",
       "      <td>0.717361</td>\n",
       "      <td>0.118280</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>relu</td>\n",
       "      <td>[4]</td>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1 / (1+epoch)**2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>HLA-A1101</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3599</td>\n",
       "      <td>998</td>\n",
       "      <td>0.857665</td>\n",
       "      <td>0.643462</td>\n",
       "      <td>0.477230</td>\n",
       "      <td>0.866213</td>\n",
       "      <td>0.617187</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>tanh</td>\n",
       "      <td>[4]</td>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1 / (1+epoch)**2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>HLA-A1101</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3599</td>\n",
       "      <td>998</td>\n",
       "      <td>0.787593</td>\n",
       "      <td>0.407871</td>\n",
       "      <td>0.359564</td>\n",
       "      <td>0.807543</td>\n",
       "      <td>0.386139</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>relu</td>\n",
       "      <td>[4]</td>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1 / (1+epoch)**2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>HLA-A1101</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3600</td>\n",
       "      <td>982</td>\n",
       "      <td>0.851256</td>\n",
       "      <td>0.655870</td>\n",
       "      <td>0.461474</td>\n",
       "      <td>0.857420</td>\n",
       "      <td>0.636197</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>tanh</td>\n",
       "      <td>[4]</td>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1 / (1+epoch)**2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>HLA-A1101</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3600</td>\n",
       "      <td>982</td>\n",
       "      <td>0.733846</td>\n",
       "      <td>0.276003</td>\n",
       "      <td>0.288950</td>\n",
       "      <td>0.726726</td>\n",
       "      <td>0.241758</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>relu</td>\n",
       "      <td>[4]</td>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1 / (1+epoch)**2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>HLA-A0203</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>3694</td>\n",
       "      <td>980</td>\n",
       "      <td>0.827452</td>\n",
       "      <td>0.657108</td>\n",
       "      <td>0.443708</td>\n",
       "      <td>0.804904</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>tanh</td>\n",
       "      <td>[4]</td>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1 / (1+epoch)**2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>HLA-A0203</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3694</td>\n",
       "      <td>980</td>\n",
       "      <td>0.745916</td>\n",
       "      <td>0.433993</td>\n",
       "      <td>0.322432</td>\n",
       "      <td>0.741698</td>\n",
       "      <td>0.406780</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>relu</td>\n",
       "      <td>[4]</td>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1 / (1+epoch)**2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>HLA-A0203</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>3695</td>\n",
       "      <td>955</td>\n",
       "      <td>0.818988</td>\n",
       "      <td>0.638649</td>\n",
       "      <td>0.432846</td>\n",
       "      <td>0.803457</td>\n",
       "      <td>0.568627</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>tanh</td>\n",
       "      <td>[4]</td>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1 / (1+epoch)**2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>HLA-A0203</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3695</td>\n",
       "      <td>955</td>\n",
       "      <td>0.724877</td>\n",
       "      <td>0.403433</td>\n",
       "      <td>0.305157</td>\n",
       "      <td>0.711808</td>\n",
       "      <td>0.322251</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>relu</td>\n",
       "      <td>[4]</td>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1 / (1+epoch)**2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>HLA-A0203</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>3695</td>\n",
       "      <td>984</td>\n",
       "      <td>0.795905</td>\n",
       "      <td>0.561261</td>\n",
       "      <td>0.397605</td>\n",
       "      <td>0.794590</td>\n",
       "      <td>0.532258</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>tanh</td>\n",
       "      <td>[4]</td>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1 / (1+epoch)**2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>HLA-A0203</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3695</td>\n",
       "      <td>984</td>\n",
       "      <td>0.743235</td>\n",
       "      <td>0.409165</td>\n",
       "      <td>0.323411</td>\n",
       "      <td>0.732820</td>\n",
       "      <td>0.317848</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>relu</td>\n",
       "      <td>[4]</td>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1 / (1+epoch)**2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       allele  fold_num  model_num  train_size  test_size  train_auc  \\\n",
       "0   HLA-A0201         0          0        6376       1525   0.895284   \n",
       "1   HLA-A0201         0          1        6376       1525   0.826558   \n",
       "2   HLA-A0201         1          0        6377       1539   0.885063   \n",
       "3   HLA-A0201         1          1        6377       1539   0.849540   \n",
       "4   HLA-A0201         2          0        6377       1423   0.871091   \n",
       "5   HLA-A0201         2          1        6377       1423   0.855029   \n",
       "6   HLA-A0301         3          0        4094       1134   0.800724   \n",
       "7   HLA-A0301         3          1        4094       1134   0.705915   \n",
       "8   HLA-A0301         4          0        4094       1073   0.814982   \n",
       "9   HLA-A0301         4          1        4094       1073   0.763060   \n",
       "10  HLA-A0301         5          0        4094       1084   0.820866   \n",
       "11  HLA-A0301         5          1        4094       1084   0.729144   \n",
       "12  HLA-A1101         6          0        3599       1019   0.850511   \n",
       "13  HLA-A1101         6          1        3599       1019   0.715559   \n",
       "14  HLA-A1101         7          0        3599        998   0.857665   \n",
       "15  HLA-A1101         7          1        3599        998   0.787593   \n",
       "16  HLA-A1101         8          0        3600        982   0.851256   \n",
       "17  HLA-A1101         8          1        3600        982   0.733846   \n",
       "18  HLA-A0203         9          0        3694        980   0.827452   \n",
       "19  HLA-A0203         9          1        3694        980   0.745916   \n",
       "20  HLA-A0203        10          0        3695        955   0.818988   \n",
       "21  HLA-A0203        10          1        3695        955   0.724877   \n",
       "22  HLA-A0203        11          0        3695        984   0.795905   \n",
       "23  HLA-A0203        11          1        3695        984   0.743235   \n",
       "\n",
       "    train_f1  train_tau  test_auc   test_f1      ...        model_impute  \\\n",
       "0   0.587408   0.517057  0.892627  0.540448      ...               False   \n",
       "1   0.099691   0.413170  0.819003  0.043796      ...               False   \n",
       "2   0.492090   0.496178  0.894675  0.408759      ...               False   \n",
       "3   0.398695   0.445013  0.850579  0.366300      ...               False   \n",
       "4   0.513023   0.467363  0.874031  0.472998      ...               False   \n",
       "5   0.250103   0.440961  0.863000  0.226328      ...               False   \n",
       "6   0.460327   0.352416  0.789823  0.474725      ...               False   \n",
       "7   0.000000   0.249910  0.698282  0.000000      ...               False   \n",
       "8   0.495316   0.390080  0.844880  0.430380      ...               False   \n",
       "9   0.192000   0.320746  0.755124  0.210863      ...               False   \n",
       "10  0.509576   0.396576  0.801169  0.461176      ...               False   \n",
       "11  0.000000   0.292090  0.677374  0.000000      ...               False   \n",
       "12  0.656062   0.464920  0.859400  0.678843      ...               False   \n",
       "13  0.120120   0.285154  0.717361  0.118280      ...               False   \n",
       "14  0.643462   0.477230  0.866213  0.617187      ...               False   \n",
       "15  0.407871   0.359564  0.807543  0.386139      ...               False   \n",
       "16  0.655870   0.461474  0.857420  0.636197      ...               False   \n",
       "17  0.276003   0.288950  0.726726  0.241758      ...               False   \n",
       "18  0.657108   0.443708  0.804904  0.586957      ...               False   \n",
       "19  0.433993   0.322432  0.741698  0.406780      ...               False   \n",
       "20  0.638649   0.432846  0.803457  0.568627      ...               False   \n",
       "21  0.403433   0.305157  0.711808  0.322251      ...               False   \n",
       "22  0.561261   0.397605  0.794590  0.532258      ...               False   \n",
       "23  0.409165   0.323411  0.732820  0.317848      ...               False   \n",
       "\n",
       "    model_activation model_layer_sizes model_batch_size  \\\n",
       "0               tanh               [4]              128   \n",
       "1               relu               [4]              128   \n",
       "2               tanh               [4]              128   \n",
       "3               relu               [4]              128   \n",
       "4               tanh               [4]              128   \n",
       "5               relu               [4]              128   \n",
       "6               tanh               [4]              128   \n",
       "7               relu               [4]              128   \n",
       "8               tanh               [4]              128   \n",
       "9               relu               [4]              128   \n",
       "10              tanh               [4]              128   \n",
       "11              relu               [4]              128   \n",
       "12              tanh               [4]              128   \n",
       "13              relu               [4]              128   \n",
       "14              tanh               [4]              128   \n",
       "15              relu               [4]              128   \n",
       "16              tanh               [4]              128   \n",
       "17              relu               [4]              128   \n",
       "18              tanh               [4]              128   \n",
       "19              relu               [4]              128   \n",
       "20              tanh               [4]              128   \n",
       "21              relu               [4]              128   \n",
       "22              tanh               [4]              128   \n",
       "23              relu               [4]              128   \n",
       "\n",
       "   model_fraction_negative  model_n_training_epochs  \\\n",
       "0                      0.2                        3   \n",
       "1                      0.2                        3   \n",
       "2                      0.2                        3   \n",
       "3                      0.2                        3   \n",
       "4                      0.2                        3   \n",
       "5                      0.2                        3   \n",
       "6                      0.2                        3   \n",
       "7                      0.2                        3   \n",
       "8                      0.2                        3   \n",
       "9                      0.2                        3   \n",
       "10                     0.2                        3   \n",
       "11                     0.2                        3   \n",
       "12                     0.2                        3   \n",
       "13                     0.2                        3   \n",
       "14                     0.2                        3   \n",
       "15                     0.2                        3   \n",
       "16                     0.2                        3   \n",
       "17                     0.2                        3   \n",
       "18                     0.2                        3   \n",
       "19                     0.2                        3   \n",
       "20                     0.2                        3   \n",
       "21                     0.2                        3   \n",
       "22                     0.2                        3   \n",
       "23                     0.2                        3   \n",
       "\n",
       "    model_embedding_output_dim  model_pretrain_decay  \\\n",
       "0                            8      1 / (1+epoch)**2   \n",
       "1                            8      1 / (1+epoch)**2   \n",
       "2                            8      1 / (1+epoch)**2   \n",
       "3                            8      1 / (1+epoch)**2   \n",
       "4                            8      1 / (1+epoch)**2   \n",
       "5                            8      1 / (1+epoch)**2   \n",
       "6                            8      1 / (1+epoch)**2   \n",
       "7                            8      1 / (1+epoch)**2   \n",
       "8                            8      1 / (1+epoch)**2   \n",
       "9                            8      1 / (1+epoch)**2   \n",
       "10                           8      1 / (1+epoch)**2   \n",
       "11                           8      1 / (1+epoch)**2   \n",
       "12                           8      1 / (1+epoch)**2   \n",
       "13                           8      1 / (1+epoch)**2   \n",
       "14                           8      1 / (1+epoch)**2   \n",
       "15                           8      1 / (1+epoch)**2   \n",
       "16                           8      1 / (1+epoch)**2   \n",
       "17                           8      1 / (1+epoch)**2   \n",
       "18                           8      1 / (1+epoch)**2   \n",
       "19                           8      1 / (1+epoch)**2   \n",
       "20                           8      1 / (1+epoch)**2   \n",
       "21                           8      1 / (1+epoch)**2   \n",
       "22                           8      1 / (1+epoch)**2   \n",
       "23                           8      1 / (1+epoch)**2   \n",
       "\n",
       "    model_dropout_probability model_max_ic50  \n",
       "0                         0.5          50000  \n",
       "1                         0.5          50000  \n",
       "2                         0.5          50000  \n",
       "3                         0.5          50000  \n",
       "4                         0.5          50000  \n",
       "5                         0.5          50000  \n",
       "6                         0.5          50000  \n",
       "7                         0.5          50000  \n",
       "8                         0.5          50000  \n",
       "9                         0.5          50000  \n",
       "10                        0.5          50000  \n",
       "11                        0.5          50000  \n",
       "12                        0.5          50000  \n",
       "13                        0.5          50000  \n",
       "14                        0.5          50000  \n",
       "15                        0.5          50000  \n",
       "16                        0.5          50000  \n",
       "17                        0.5          50000  \n",
       "18                        0.5          50000  \n",
       "19                        0.5          50000  \n",
       "20                        0.5          50000  \n",
       "21                        0.5          50000  \n",
       "22                        0.5          50000  \n",
       "23                        0.5          50000  \n",
       "\n",
       "[24 rows x 22 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with joblib.parallel_backend('distributed', scheduler_host='127.0.0.1:8786'):\n",
    "    df = mhcflurry_cloud.train_across_models_and_folds(folds, models)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
